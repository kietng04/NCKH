{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66691c67",
   "metadata": {},
   "source": [
    "# Machine Learning Mastery With Python\n",
    "## Chương 7-8: Tiền xử lý dữ liệu & Lựa chọn đặc trưng\n",
    "\n",
    "\n",
    "Notebook này hướng dẫn các bước tiền xử lý dữ liệu (chuẩn hóa, chuyển đổi, nhị phân hóa) và lựa chọn đặc trưng (feature selection) để chuẩn bị cho các mô hình Machine Learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42941b",
   "metadata": {},
   "source": [
    "## Mục lục\n",
    "1. [Chuẩn bị dữ liệu](#chuan-bi)\n",
    "2. [Rescale dữ liệu về [0,1] (MinMaxScaler)](#rescale)\n",
    "3. [Chuẩn hóa dữ liệu về phân phối chuẩn (StandardScaler)](#standardize)\n",
    "4. [Chuẩn hóa vector về độ dài 1 (Normalizer)](#normalize)\n",
    "5. [Nhị phân hóa dữ liệu (Binarizer)](#binarize)\n",
    "6. [Lựa chọn đặc trưng đơn biến (SelectKBest)](#univariate)\n",
    "7. [Loại trừ đặc trưng đệ quy (RFE)](#rfe)\n",
    "8. [Phân tích thành phần chính (PCA)](#pca)\n",
    "9. [Đánh giá tầm quan trọng đặc trưng (ExtraTrees)](#importance)\n",
    "10. [Tổng kết](#tong-ket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09e6be",
   "metadata": {},
   "source": [
    "<a id=\"chuan-bi\"></a>\n",
    "## 1. Chuẩn bị dữ liệu\n",
    "\n",
    "Ở đây, chúng ta sẽ sử dụng dataset Pima Indians Diabetes (dạng CSV) với 8 thuộc tính đầu vào và 1 nhãn đầu ra (class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb882813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Đọc dữ liệu\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "\n",
    "# Tách X (features) và y (label)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "print(\"Kích thước X:\", X.shape)  # (768, 8)\n",
    "print(\"5 dòng đầu của X:\")\n",
    "print(X.head())\n",
    "print(\"5 giá trị đầu của y:\", y.values[:5])\n",
    "\n",
    "# X chứa các đặc trưng đầu vào\n",
    "# y là nhãn (0 hoặc 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a11dec",
   "metadata": {},
   "source": [
    "<a id=\"rescale\"></a>\n",
    "## 2. Rescale dữ liệu về [0,1] bằng MinMaxScaler\n",
    "\n",
    "**Mục đích:**  \n",
    "Một số thuật toán (KNN, SVM, Neural Network,...) nhạy cảm với thang đo của dữ liệu. Rescale đưa mọi thuộc tính về cùng thang [0,1] để so sánh công bằng hơn.\n",
    "\n",
    "**Công thức:**  \n",
    "\\[\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "print(\"5 dòng đầu sau khi rescale về [0,1]:\")\n",
    "print(X_rescaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b47181",
   "metadata": {},
   "source": [
    "<a id=\"standardize\"></a>\n",
    "## 3. Chuẩn hóa dữ liệu về phân phối chuẩn (StandardScaler)\n",
    "\n",
    "**Mục đích:**  \n",
    "Standardization giúp dữ liệu có trung bình 0 và độ lệch chuẩn 1. Phù hợp cho các mô hình tuyến tính (Logistic Regression, SVM, KNN...).\n",
    "\n",
    "**Công thức:**  \n",
    "\\[\n",
    "X_{\\text{standardized}} = \\frac{X - \\mu}{\\sigma}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "print(\"5 dòng đầu sau khi chuẩn hóa (mean=0, std=1):\")\n",
    "print(X_standardized[:5])\n",
    "print(\"Mean sau chuẩn hóa (gần 0):\", np.mean(X_standardized, axis=0))\n",
    "print(\"Std sau chuẩn hóa (gần 1):\", np.std(X_standardized, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71c252",
   "metadata": {},
   "source": [
    "<a id=\"normalize\"></a>\n",
    "## 4. Chuẩn hóa vector về độ dài 1 (Normalizer)\n",
    "\n",
    "**Mục đích:**  \n",
    "Phù hợp khi bạn quan tâm đến hướng của vector đặc trưng hơn là độ lớn (ví dụ: KNN, Cosine similarity).\n",
    "\n",
    "**Công thức:**  \n",
    "\\[\n",
    "\\vec{x}_{\\text{norm}} = \\frac{\\vec{x}}{||\\vec{x}||}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "print(\"5 dòng đầu sau khi normalize (vector có norm=1):\")\n",
    "print(X_normalized[:5])\n",
    "\n",
    "# Kiểm tra norm của từng vector\n",
    "print(\"Norm của 5 dòng đầu:\", np.linalg.norm(X_normalized[:5], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e442b0",
   "metadata": {},
   "source": [
    "<a id=\"binarize\"></a>\n",
    "## 5. Nhị phân hóa dữ liệu (Binarizer)\n",
    "\n",
    "**Mục đích:**  \n",
    "Chuyển giá trị lớn hơn threshold thành 1, còn lại là 0. Thường dùng cho dữ liệu đặc biệt hoặc tạo đặc trưng mới.\n",
    "\n",
    "**Ví dụ:** threshold=5, giá trị >5 thành 1, <=5 thành 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ee168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=5.0)\n",
    "X_binarized = binarizer.fit_transform(X)\n",
    "print(\"5 dòng đầu sau khi binarize (threshold=5):\")\n",
    "print(X_binarized[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce4b13",
   "metadata": {},
   "source": [
    "<a id=\"univariate\"></a>\n",
    "## 6. Lựa chọn đặc trưng đơn biến (SelectKBest với chi2)\n",
    "\n",
    "**Mục đích:**  \n",
    "Chọn ra k đặc trưng tốt nhất dựa trên kiểm định thống kê giữa từng thuộc tính và nhãn (ở đây dùng chi2 cho phân loại).\n",
    "\n",
    "**Lưu ý:**  \n",
    "- Chi2 chỉ dùng cho dữ liệu không âm (non-negative).\n",
    "- Nên dùng MinMaxScaler trước nếu dữ liệu có giá trị âm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Đảm bảo dữ liệu không âm\n",
    "X_nonneg = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X_nonneg, y)\n",
    "print(\"Điểm chi2 của từng thuộc tính:\")\n",
    "print(fit.scores_)\n",
    "print(\"Chọn ra 4 đặc trưng tốt nhất (5 dòng đầu):\")\n",
    "print(fit.transform(X_nonneg)[:5])\n",
    "print(\"Các cột được chọn:\", np.array(names[:-1])[fit.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e9e8c",
   "metadata": {},
   "source": [
    "<a id=\"rfe\"></a>\n",
    "## 7. Loại trừ đặc trưng đệ quy (RFE)\n",
    "\n",
    "**Mục đích:**  \n",
    "RFE loại bỏ dần các đặc trưng kém quan trọng nhất dựa vào mô hình (Logistic Regression, SVM, ...).  \n",
    "Giúp tìm ra tập đặc trưng tối ưu cho mô hình.\n",
    "\n",
    "**Cách dùng:**  \n",
    "- Chọn số đặc trưng muốn giữ lại (n_features_to_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3baf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(model, n_features_to_select=3)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Các đặc trưng được chọn (True là chọn):\")\n",
    "print(fit.support_)\n",
    "print(\"Thứ tự quan trọng (1 là quan trọng nhất):\")\n",
    "print(fit.ranking_)\n",
    "print(\"Tên các cột được chọn:\", np.array(names[:-1])[fit.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931efcd2",
   "metadata": {},
   "source": [
    "<a id=\"pca\"></a>\n",
    "## 8. Phân tích thành phần chính (PCA)\n",
    "\n",
    "**Mục đích:**  \n",
    "PCA giúp giảm chiều dữ liệu bằng cách tạo ra các thành phần mới (principal components) giữ lại phần lớn phương sai.  \n",
    "Có thể dùng để trực quan hóa dữ liệu hoặc giảm nhiễu.\n",
    "\n",
    "**Lưu ý:**  \n",
    "- PCA là kỹ thuật không giám sát (unsupervised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "print(\"Tỉ lệ phương sai giải thích bởi mỗi thành phần:\", fit.explained_variance_ratio_)\n",
    "print(\"Các thành phần chính (principal components):\")\n",
    "print(fit.components_)\n",
    "print(\"Dữ liệu sau PCA (5 dòng đầu):\")\n",
    "print(fit.transform(X)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d1277",
   "metadata": {},
   "source": [
    "<a id=\"importance\"></a>\n",
    "## 9. Đánh giá tầm quan trọng đặc trưng (ExtraTrees)\n",
    "\n",
    "**Mục đích:**  \n",
    "Dùng mô hình cây (ExtraTrees) để đánh giá mức độ quan trọng của từng thuộc tính với dự đoán nhãn.  \n",
    "Thường dùng để loại bỏ đặc trưng kém quan trọng.\n",
    "\n",
    "**Lưu ý:**  \n",
    "- Kết quả là một vector độ quan trọng (feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7fe0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "print(\"Độ quan trọng của từng đặc trưng:\")\n",
    "for name, score in zip(names[:-1], model.feature_importances_):\n",
    "    print(f\"{name}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61adc34b",
   "metadata": {},
   "source": [
    "<a id=\"tong-ket\"></a>\n",
    "## 10. Tổng kết\n",
    "\n",
    "- Đã thực hiện các bước tiền xử lý dữ liệu: rescale, standardize, normalize, binarize.\n",
    "- Đã thử nghiệm nhiều kỹ thuật lựa chọn đặc trưng: SelectKBest, RFE, PCA, ExtraTrees.\n",
    "- Việc tiền xử lý và chọn đặc trưng giúp mô hình học máy hiệu quả, chính xác và nhanh hơn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
